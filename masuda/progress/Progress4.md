# 第4回　進度報告
### 11月10日：坂西和也
## 資料の説明
卒業研究3：様々なカーネル関数を用いたガウス過程回帰の結果を示した．

卒業研究4：回帰問題を解くのではなく，分類問題として解析に着手した．増田先生からいただいた期待値データに対して，正規分布に従うノイズを加えたデータを教師信号，乱数のみのデータを非教師信号としてデータセット作成し，ロジスティック回帰を行った．

卒業研究5：卒業研究4と同様の流れでやるが，増田先生からいただいた期待値データを0.1倍してロジスティック回帰行った

卒業研究6：卒業研究4と同様の流れでやるが，増田先生からいただいた期待値データを0.01倍してロジスティック回帰行った

卒業研究7：実験から得られるデータに近いものを確認した．

卒業研究8：ニューラルネットワークで0.1倍に関するものを再度学習した．

卒業研究9：畳み込みニューラルネットワークで0.1倍に関するものを再度学習

ロジスティック回帰：卒論レビュー用に作成したロジスティック回帰の説明

ニューラルネットワーク：卒論レビュー用に作成したニューラルネットワークの説明

畳み込みニューラルネットワーク：卒論レビュー用に作成した畳み込みニューラルネットワークの説明


## やってきたこと
卒業研究3まではガウス過程回帰を用いた回帰問題として，期待値データの復元を目指したが，ノイズが大きすぎるとカーネル関数を変更してもうまく行かなかった．（卒業研究3）

そこで回帰問題ではなく，分類問題として捉えることにした．問題として，実験することでピークを見たいのだが，実験状況の関係でいくら実験をつづけてもピークが現れないことがある．そこで，いずれピークが出るデータを教師データとし，いくら実験してもピークが出ないデータを非教師データとして分類問題を解くことにした．

まずは増田先生からいただいた期待値データをそのまま使いデータセットを作成しロジスティック回帰を行った．（卒業研究4）

次に，期待値データを0.1倍してデータセットを作成しロジスティック回帰を行った．（卒業研究5）

次に，期待値データを0.01倍してデータセットを作成しロジスティック回帰を行った．（卒業研究6）

今後テストデータは，実験から得られるデータを用いていきたいので，それ近いデータの確認をした．（卒業研究7）

テストデータを見る限り，判別の難しそうなものがいくつかあるが0.01倍にしたものを扱った時よりも簡単なように思えたので，とりあえず0.1倍でうまくいかなかったものをニューラルネットワークと畳み込みニューラルネットワークで試して学習の練習をした．（卒業研究8，9）

## 今後の予定
テストデータはどの期待値から発生したデータかはわからないので，学習する際にはすべてのピークの出方を考慮した学習が必要である．

用いたいモデルの練習はでき，いつでもスムーズに実行可能なので，来月はテストデータを考慮した学習に工夫を凝らしたい．

現在考えているのは，テストデータの縦軸がすべて異なっているため，速度-20の値で割ってある程度標準化していかないと学習ができないと予想されるので，学習データとテストデータ共に標準化をしてから学習をしてみたい．

また，実験環境が未だに理解できていないので，増田先生からもらった論文を精読する．
## 個人的：今後のイベント
- 11月
-- 15日から22日まで：統計検定，内見のため東京